dates <- read.csv(here("data/alldates.csv"))
if ("here" %in% installed.packages()) {require(here)} else {install.packages("here"); require(here)}
i_am("final_scripts/6_manual_chronologies.Rmd")
source(here("final_scripts/functions/6_manual_chronologies_functions.R"))
dates <- read.csv(here("data/alldates.csv"))
dates <- split(dates,dates$category)
mixed <- dates$`3`
mixed <- split(mixed,mixed$collectionunitid)
done <- as.numeric(unlist(sapply(dir(here("outputs/sampleages")),
function(x) return(strsplit(x,".csv")))))
which(!names(mixed) %in% done)
mixed <- mixed[!names(mixed) %in% done]
mixed
codeblocks <- sapply(mixed,makeOxcalCode)
here()
for (i in 1:length(codeblocks)){
filename <- paste0(c(here("workflow/scripts/oxcalscripts/oxcode"),names(codeblocks[i]),".txt"),
collapse = "")
print(filename)
write(codeblocks[[i]],file = filename)
}
codeblocks <- sapply(mixed,makeOxcalCode)
here()
for (i in 1:length(codeblocks)){
filename <- paste0(c(here("scripts/oxcalscripts/oxcode"),names(codeblocks[i]),".txt"),
collapse = "")
print(filename)
write(codeblocks[[i]],file = filename)
}
names(mixed)
temp <- web.results <- vector(mode = "list",
length = length(dir(here("outputs/oxcalDownloads_new"))))
if ("here" %in% installed.packages()) {require(here)} else {install.packages("here"); require(here)}
i_am("final_scripts/6_manual_chronologies.Rmd")
source(here("final_scripts/functions/6_manual_chronologies_functions.R"))
dates <- read.csv(here("data/alldates.csv"))
dates <- split(dates,dates$category)
mixed <- dates$`3`
mixed <- split(mixed,mixed$collectionunitid)
done <- as.numeric(unlist(sapply(dir(here("outputs/sampleages")),
function(x) return(strsplit(x,".csv")))))
mixed <- mixed[!names(mixed) %in% done]
mixed
codeblocks <- sapply(mixed,makeOxcalCode)
temp <- web.results <- vector(mode = "list",
length = length(dir(here("outputs/oxcalDownloads_new"))))
names(temp)
for (i in 1:length(temp)) {
temp[[i]] <- read.csv(file = paste0(c(here("outputs/oxcalDownloads_new/"), "/",
dir(here("outputs/oxcalDownloads_new/"))[i]),collapse = ""))
names(temp)[i] <- gsub(".csv","",dir(here("outputs/oxcalDownloads_new/"))[i])
}
names(temp)
which(names(mixed) %in% names(temp))
grep(names(temp),names(mixed))
names(temp)
grep(names(mixed),names(temp))
names(web.results) <- names(temp)
web.results
grepl(names(mixed),names(temp))
temp <- temp[grepl(names(mixed),names(temp))]
temp
dim(temp)
temp[1]
length(temp)
names(temp)
web.results <- vector(mode = "list", length = length(temp))
names(web.results) <- names(temp)
web.results
source(here("final_scripts/functions/6_manual_chronologies_functions.R"))
# compute the appropriate quantiles from the probability density functions in the files you downloaded
for (i in which(sapply(web.results,length) == 1)){
web.results[[i]] <- try(extractChronology.Table(temp[[i]],idtype = "geochronid"))
}
# clean up the names of the chroncontrols
for (i in 1:length(web.results)){
web.results[[i]]$chroncontrols$geochronology.labnumber <-
gsub(", .*", "",web.results[[i]]$chroncontrols$geochronology.labnumber)
}
web.results
temp[[1]]
extractChronology.Table(temp[[i]],idtype = "geochronid")
dates <- alldates <- read.csv(here("data/alldates.csv"))
dates <- split(dates,dates$category)
# compute the appropriate quantiles from the probability density functions in the files you downloaded
for (i in which(sapply(web.results,length) == 1)){
web.results[[i]] <- try(extractChronology.Table(temp[[i]],idtype = "geochronid"))
}
web.results
# clean up the names of the chroncontrols
for (i in 1:length(web.results)){
web.results[[i]]$chroncontrols$geochronology.labnumber <-
gsub(", .*", "",web.results[[i]]$chroncontrols$geochronology.labnumber)
}
web.results
filestring <- paste0(c(strsplit(names(web.results[i]),"-")[[1]][1],".csv"),collapse = "")
filestring
for (i in 1:length(web.results)){
filestring <- paste0(c(strsplit(names(web.results[i]),"-")[[1]][1],".csv"),collapse = "")
write.csv(web.results[[i]]$sampleages,
file = paste0(c(here("outputs/sampleages/"),
filestring),collapse = ""), row.names = F)
write.csv(web.results[[i]]$chroncontrols,
file = paste0(c(here("outputs/chroncontrols/"),
filestring),collapse = ""), row.names = F)
}
source("~/Github/chronologies_pub/7_compile_chronologies_functions.R")
rm(list=ls())
if ("here" %in% installed.packages()) {require(here)} else {install.packages("here"); require(here)}
i_am("final_scripts/7_compile_chronologies.Rmd")
source(here("final_scripts/functions/7_compile_chronologies_functions.R"))
inferred_sampleages <- read.csv(here("outputs/inferred_sampleages.csv"))[,1:6]
inferred_sampleages$source <- "inferred"
newchron.all$source <- "computed"
# computed analysis unit ages
fpath <- paste0(c(here(),"/workflow/outputs/sampleages"), collapse = "")
names <- data.frame(collid = gsub(".csv","",dir(path = fpath)),
path = unname(sapply(dir(path = fpath),
function(x) paste(c(fpath,"/",x),collapse = ""))))
names <- subset(names,suppressWarnings(!is.na(as.numeric(names$collid))) & grepl("csv",names$path))
newchron.all <- list.stack(apply(names,1,function(x) {
csv <- try(read.csv(file = x["path"]),silent = T)
if (class(csv) == "data.frame") {
return(suppressWarnings(cbind(collid = as.numeric(x["collid"]),csv)))}
}),use.names = F)
colnames(newchron.all)[1] <- "collectionunitid"
colnames(newchron.all)
# computed analysis unit ages
fpath <- paste0(c(here(),"outputs/sampleages"), collapse = "")
names <- data.frame(collid = gsub(".csv","",dir(path = fpath)),
path = unname(sapply(dir(path = fpath),
function(x) paste(c(fpath,"/",x),collapse = ""))))
names <- subset(names,suppressWarnings(!is.na(as.numeric(names$collid))) & grepl("csv",names$path))
names
fpath
# computed analysis unit ages
fpath <- paste0(c(here(,"outputs/sampleages"), collapse = ""))
# computed analysis unit ages
fpath <- paste0(c(here(,"outputs/sampleages")), collapse = "")
c(here(,"outputs/sampleages"))
# computed analysis unit ages
fpath <- paste0(c(here("outputs/sampleages")), collapse = "")
fpath
names <- data.frame(collid = gsub(".csv","",dir(path = fpath)),
path = unname(sapply(dir(path = fpath),
function(x) paste(c(fpath,"/",x),collapse = ""))))
names <- subset(names,suppressWarnings(!is.na(as.numeric(names$collid))) & grepl("csv",names$path))
names
newchron.all <- list.stack(apply(names,1,function(x) {
csv <- try(read.csv(file = x["path"]),silent = T)
if (class(csv) == "data.frame") {
return(suppressWarnings(cbind(collid = as.numeric(x["collid"]),csv)))}
}),use.names = F)
colnames(newchron.all)[1] <- "collectionunitid"
head(newchron.all)
inferred_sampleages <- read.csv(here("outputs/inferred_sampleages.csv"))[,1:6]
inferred_sampleages$source <- "inferred"
newchron.all$source <- "computed"
newchron.all <- as.data.frame(rbind(newchron.all,subset(inferred_sampleages,inferred_sampleages$collectionunitid %in% newchron.all$collectionunitid)))
table(newchron.all$source)
colnames(inferred_sampleages)
inferred_sampleages <- read.csv(here("outputs/inferred_sampleages.csv"))[,1:6]
inferred_sampleages <- subset(inferred_sampleages,
inferred_sampleages$collectionunitid %in% newchron.all$collectionunitid)
dim(inferred_sampleages)
inferred_sampleages$source <- "inferred"
newchron.all$source <- "computed"
newchron.all <- as.data.frame(rbind(newchron.all,subset(inferred_sampleages,inferred_sampleages$collectionunitid %in% newchron.all$collectionunitid)))
table(newchron.all$source)
# computed analysis unit ages
fpath <- paste0(c(here("outputs/sampleages")), collapse = "")
names <- data.frame(collid = gsub(".csv","",dir(path = fpath)),
path = unname(sapply(dir(path = fpath),
function(x) paste(c(fpath,"/",x),collapse = ""))))
names <- subset(names,suppressWarnings(!is.na(as.numeric(names$collid))) & grepl("csv",names$path))
newchron.all <- list.stack(apply(names,1,function(x) {
csv <- try(read.csv(file = x["path"]),silent = T)
if (class(csv) == "data.frame") {
return(suppressWarnings(cbind(collid = as.numeric(x["collid"]),csv)))}
}),use.names = F)
colnames(newchron.all)[1] <- "collectionunitid"
inferred_sampleages <- read.csv(here("outputs/inferred_sampleages.csv"))[,1:6]
inferred_sampleages <- subset(inferred_sampleages,
inferred_sampleages$collectionunitid %in% newchron.all$collectionunitid)
inferred_sampleages$source <- "inferred"
newchron.all$source <- "computed"
newchron.all <- as.data.frame(rbind(newchron.all,inferred_sampleages))
table(newchron.all$source)
fpath
names[1]
names[1,]
# computed analysis unit ages
fpath <- here("outputs/sampleages")
fpath
names <- data.frame(collid = gsub(".csv","",dir(path = fpath)),
path = unname(sapply(dir(path = fpath),
function(x) paste(c(fpath,"/",x),collapse = ""))))
names[1,]
fpath2 <- here("outputs/chroncontrols")
names2 <- data.frame(collid = gsub(".csv","",dir(path = fpath2)),
path = unname(sapply(dir(path = fpath2),
function(x) paste(c(fpath2,"/",x),collapse = ""))))
names2 <- subset(names2,suppressWarnings(!is.na(as.numeric(names2$collid))))
newchron.ctrls <- list.stack(apply(names2,1,function(x) {
csv <- try(read.csv(file = x["path"]),silent = T)
if (class(csv) == "data.frame") {
return(suppressWarnings(cbind(collid = as.numeric(x["collid"]),csv)))}
}),use.names = F)
colnames(newchron.ctrls)[1] <- "collectionunitid"
dim(newchron.ctrls)
future <- which(newchron.all$sampleages.ageyounger < -75)
newchron.all[future,"sampleages.ageyounger"] <- -75
chroncontroltypes <- get_table("chroncontroltypes",limit = 999)[,1:3]
if (!exists("alldates")) alldates <- read.csv(here("workflow/data/alldates.csv"))
chroncontroltypes <- get_table("chroncontroltypes",limit = 999)[,1:3]
if (!exists("alldates")) alldates <- read.csv(here("data/alldates.csv"))
temp <- left_join(newchron.ctrls,alldates[,c("geochronid","geochrontypeid","agetypeid")])
table(temp$geochrontypeid)
typeindex <- data.frame(table(temp$geochrontypeid))
#add more types if necessary here!
typeindex$chroncontroltype <- c("Palaeomagnetic","Argon-argon",
"Radiocarbon, calibrated, Bayesian modelled",
"Optically stimulated luminescence",
"Thermoluminescence","Uranium-series")
typeindex <- left_join(typeindex[c("Var1","chroncontroltype")],chroncontroltypes)
temp <- left_join(temp,typeindex[,c("Var1","chroncontroltype","chroncontroltypeid")],
by = join_by(geochrontypeid == Var1))
temp[which(temp$geochrontypeid == "Carbon-14" & temp$agetypeid %in% c("calendar yr BP","cal yr BP")),"chroncontroltype"] <- "Calibrated radiocarbon years BP"
temp[which(temp$geochrontypeid == "Carbon-14" & temp$agetypeid %in% c("calendar yr BP","cal yr BP")),"chroncontroltypeid"] <- 17
newchron.ctrls <- temp[,c(colnames(newchron.ctrls),"chroncontroltypeid")]
source(here("final_scripts/functions/7_compile_chronologies_functions.R"))
newchron.range <- list.stack(tapply(newchron.all,newchron.all$collectionunitid,
dfbounds, simplify = F))
timeinfo <- cbind(filename = dir(here("workflow/outputs/sampleages")),
list.stack(sapply(dir(here("workflow/outputs/sampleages"),full.names = T),
file.info, simplify = F)))
timeinfo$collectionunitid <- unlist(sapply(timeinfo$filename,function(x) strsplit(x,".csv")))
timeinfo$dateprepared <- unlist(sapply(timeinfo$mtime,function(x) strsplit(as.character(x)," ")[[1]][1]))
newchron.range <- merge(newchron.range,timeinfo[,c("collectionunitid","dateprepared")])
newchron.range <- list.stack(tapply(newchron.all,newchron.all$collectionunitid,
dfbounds, simplify = F))
head(newchron.range)
timeinfo <- cbind(filename = dir(here("outputs/sampleages")),
list.stack(sapply(dir(here("outputs/sampleages"),full.names = T),
file.info, simplify = F)))
timeinfo$collectionunitid <- unlist(sapply(timeinfo$filename,function(x) strsplit(x,".csv")))
timeinfo$dateprepared <- unlist(sapply(timeinfo$mtime,function(x) strsplit(as.character(x)," ")[[1]][1]))
newchron.range <- merge(newchron.range,timeinfo[,c("collectionunitid","dateprepared")])
newchron.range$chronologies.notes <- NA
#assign temporary chronids
newchron.range$TEMP_chronid <- paste0("TEMP",1:nrow(newchron.range))
newchron.all <- left_join(newchron.all,
newchron.range[,c("collectionunitid","agemodel","TEMP_chronid")],
by = join_by(collectionunitid == collectionunitid,
chronology.agemodel == agemodel),
relationship = "many-to-one")
temp <- distinct(inner_join(newchron.ctrls,alldates[,c("geochronid","analysisunitid")]))
temp[,c(1:2,4:8)] <- apply(temp[,c(1:2,4:8)],2,as.numeric)
newchron.all[,c(1:2,4:6)] <- apply(newchron.all[,c(1:2,4:6)],2,as.numeric)
newchron.sampleages <- split(newchron.all,newchron.all$chronology.agemodel)
templist <- list(bounds = distinct(left_join(temp,
distinct(newchron.sampleages$bounds[,c("analysisunitid","TEMP_chronid")]))),
event = distinct(left_join(temp,
distinct(newchron.sampleages$event[,c("analysisunitid","TEMP_chronid")]))))
templist$bounds <- left_join(templist$bounds,subset(newchron.all,newchron.all$chronology.agemodel == "bounds")[,c("analysisunitid","TEMP_chronid")],relationship = "many-to-many")
templist$event <- left_join(templist$event,subset(newchron.all,newchron.all$chronology.agemodel == "event")[,c("analysisunitid","TEMP_chronid")],relationship = "many-to-many")
newchron.ctrls <- distinct(list.stack(templist))
dim(newchron.ctrls)
inferred_chroncontrols <- read.csv(here("workflow/outputs/inferred_chroncontrols.csv"))
inferred_chroncontrols <- read.csv(here("outputs/inferred_chroncontrols.csv"))
inferred_chroncontrols <- distinct(subset(inferred_chroncontrols, inferred_chroncontrols$collectionunitid %in% newchron.range$collectionunitid))
temp <- distinct(left_join(inferred_chroncontrols[,1:9],newchron.all[,c("collectionunitid","chronology.agemodel","TEMP_chronid")],by = join_by(collectionunitid,chronology.agemodel), relationship = "many-to-many"))
newchron.ctrls <- distinct(rbind(newchron.ctrls,temp[,-9]))
future_chronids <- unique(newchron.all[future,"TEMP_chronid"])
newchron.range[which(newchron.range$TEMP_chronid %in% future_chronids),
"chronologies.notes"] <- "younger age limits truncated at publication date (2025 CE)"
dim(newchron.ctrls)
apply(newchron.ctrls,2,function(x) any(is.na(x)))
here()
write.csv(newchron.ctrls,here("workflow/outputs/new_caldates.csv"), row.names = F)
write.csv(newchron.ctrls,here("outputs/new_caldates.csv"), row.names = F)
write.csv(newchron.range,here("outputs/new_chronologies.csv"), row.names = F)
write.csv(newchron.all,here("outputs/new_sampleages.csv"), row.names = F)
rm(list=ls())
if ("here" %in% installed.packages()) {require(here)} else {install.packages("here"); require(here)}
i_am("final_scripts/9_get_single_site.Rmd")
source(here("final_scripts/functions/9_single_site_functions.R"))
source(here("final_scripts/functions/9_single_site_functions.R"))
site_selection <- 5120
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
source(here("final_scripts/functions/9_single_site_functions.R"))
site_selection <- 5120
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
get_smallvert_datasets <- function(vert_and_chron, site.geochrons,datasets) {
require(httr);require(jsonlite);require(dplyr);require(rlist)
if (!file.exists(here("data/smallmammaltaxa.csv"))) {
source(here("final_scripts/functions/filter_taxa.R"))}
smalltaxa <- read.csv(here("data/smallmammaltaxa.csv"))
vert.datasets <- unique(intersect(subset(vert_and_chron,
vert_and_chron$collectionunitid %in% site.geochrons$collectionunitid)[,"datasetid"],
subset(datasets,datasets$datasettype == "vertebrate fauna")$datasetid))
temp <- vector(mode = "list",length = length(vert.datasets))
print(paste0(c("Downloading taxon data for",length(vert.datasets),"datasets..."),collapse = " "))
for (i in 1:length(vert.datasets)) {
verts.temp <- try(get_from_tilia(values = vert.datasets[i],
params = "datasetid",
meth = "getdatasetvariables")$data)
vals <- smalltaxa[na.omit(match(verts.temp[,"taxoncode"],smalltaxa[,"taxoncode"])), "taxonid"]
temp[[i]] <- data.frame(datasetid = rep(vert.datasets[i],length(vals)),
taxonid = vals)
}
taxonids <- distinct(rlist::list.stack(temp))
smallmamm.colls <- unique(subset(vert_and_chron,
vert_and_chron$datasetid %in% taxonids$datasetid)$collectionunitid)
print(paste0(c("Found",length(smallmamm.colls),"datasets with small mammals."),collapse = " "))
return(smallmamm.colls)
}
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
loadGeochronTable <- function() {
if (file.exists(here("data/ndb_geochronology.csv"))) {
geochronology.table <- read.csv(here("data/ndb_geochronology.csv"))
}
if (exists("geochronology.table")) {
if (checkRecent(geochronology.table) == F) {rm(geochronology.table)}}
if (!exists("geochronology.table")) {
print("Downloading table 'geochronology'...")
geochronology.table <- distinct(get_table("geochronology", limit = 99999999))
write.csv(geochronology.table, here("data/ndb_geochronology.csv"), row.names = F)
}
return(geochronology.table)
}
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
checkRecent <- function(x) {
if (max(as.Date(x$recdatemodified), na.rm = T) > seq(Sys.Date(), length = 2, by = "-1 month")[2]) {
return("TRUE")
} else return("FALSE")
}
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
cleandates <- function(data){
drop <- which(is.na(data$age) | is.na(data$errorolder) | is.na(data$erroryounger) |
data$age < 10 | data$errorolder == 0 |
data$infinite == TRUE | data$human == TRUE | data$rejected == TRUE)
if (length(drop) > 0) {result <- data[-drop,]} else {result <- data}
return(result)
}
site_selection <- 5120
add.dates <- get_site_geochrons(site_selection,geochronology.table = geochronology.table,agelimit = 30000)
add.dates
